import asyncio
import logging
from typing import Tuple

import httpx
from openai import AsyncOpenAI

import verifiers as vf
from verifiers.types import Messages, State


def setup_client(
    api_base_url, api_key, timeout=600.0, max_connections=100, max_keepalive_connections=50, max_retries=3
):
    timeout_obj = httpx.Timeout(timeout, connect=5.0)
    limits = httpx.Limits(max_connections=max_connections, max_keepalive_connections=max_keepalive_connections)
    http_client = httpx.AsyncClient(limits=limits, timeout=timeout_obj)
    return AsyncOpenAI(base_url=api_base_url, api_key=api_key, max_retries=max_retries, http_client=http_client)


ANSWERER_SYSTEM_PROMPT = """
You are playing twenty questions. You are the player who comes up with the thing to be guessed, and you chose: {answer}

The other player is trying to guess {answer} based on your answers to their yes/no questions.

YOUR JOB: Answer their questions about "{answer}" with Yes, No, or I don't know.

Do not overthink - just answer the question about {answer}

Expected format:
{format_str}

Examples: <answer>Yes</answer> or <answer>No</answer> or <answer>I don't know</answer>
"""

ANSWERER_USER_PROMPT = "{question}"

QUESTIONER_SYSTEM_PROMPT = """
You are playing twenty questions, your job is to guess what the user is thinking of by asking yes/no questions. 

Make sure you read the game instructions carefully, and always follow the required format.

Required format:
{format_str}
"""

WINNING_MESSAGE = "Yes! The answer was '{answer}'. You got it!"

MAX_QUESTIONS_MESSAGE = "No! The answer was '{answer}'. You lost!"

INITIAL_QUESTION_MESSAGE = """
Rules:
- You have up to 20 questions.
- After the 20th question you will be allowed a final guess.
- You may make your guess early if you wish, for the cost of one of your remaining questions.

CRITICAL: Never include both <question> and <guess> in the same message.

Ask your first yes/no question to begin.
"""

ANSWERER_MAX_RETRIES = 3
ANSWERER_RETRY_BACKOFF_SECONDS = 1.0

INVALID_XML_FORMAT_MESSAGE = (
    "Please format your response properly using the required XML tags. Expected format:\n{format_str}"
)

INVALID_NESTED_XML_FORMAT_MESSAGE = "Don't nest XML tags in your response. Expected format:\n{format_str}"

INCORRECT_GUESS_MESSAGE = "No, that's not correct. You have {remaining_questions} questions left."

REMAINING_QUESTIONS_RESPONSE_TEMPLATE = "{answer_text}\nYou have {remaining_questions} questions left."

FINAL_GUESS_PROMPT_MESSAGE_TEMPLATE = (
    "{answer_text}\nYou've used all 20 questions. Please make your final guess, what am I thinking of?"
)


class TwentyQuestionsEnv(vf.MultiTurnEnv):
    """
    A twenty questions environment that uses an external LLM to answer questions generated by the model:

    1. QUESTIONER LLM (being evaluated): Asks questions, tries to guess the secret
    2. ANSWERER LLM (environment): Knows the secret, answers yes/no questions
    """

    def __init__(
        self,
        answerer_client: AsyncOpenAI,
        answerer_model: str,
        **kwargs,
    ):
        super().__init__(max_turns=-1, **kwargs)

        self.answerer_client = answerer_client
        self.answerer_model = answerer_model
        self.answerer_sampling_args = {"temperature": 0.3}

        self.answerer_parser = vf.XMLParser(
            fields=["answer"],
            answer_field="answer",
        )

        self.answerer_system_prompt = ANSWERER_SYSTEM_PROMPT.format(
            answer="{answer}",
            format_str=self.answerer_parser.get_format_str(),
        )

        self.logger = logging.getLogger(f"verifiers.envs.{self.__class__.__name__}")

    async def setup_state(self, state: State, **kwargs) -> State:
        """Initialize game state with the answer from the current dataset row."""
        state["questions_asked"] = 0
        state["game_over"] = False
        state["final_message_sent"] = False
        return state

    async def is_completed(self, messages: Messages, state: State, **kwargs) -> bool:
        """Game is complete after final message has been sent."""
        game_over = state.get("game_over", False)
        final_message_sent = state.get("final_message_sent", False)

        return game_over and final_message_sent

    async def env_response(self, messages: Messages, state: State, **kwargs) -> Tuple[Messages, State]:
        """
        Generate environment response using external LLM.
        The LLM knows the answer and answers yes/no questions or handles guesses.
        """
        if state.get("final_message_sent", False):
            state["game_over"] = True
            return [], state

        answer = state["answer"]
        questions_asked = state["questions_asked"]

        last_message_content = messages[-1]["content"]

        parsed = self.parser.parse(last_message_content)

        if not parsed or (
            not (hasattr(parsed, "guess") and parsed.guess) and not (hasattr(parsed, "question") and parsed.question)
        ):
            return [
                {
                    "role": "user",
                    "content": INVALID_XML_FORMAT_MESSAGE.format(format_str=self.parser.get_format_str()),
                }
            ], state

        if hasattr(parsed, "guess") and parsed.guess:
            guess = parsed.guess.strip().lower()
            answer_lower = answer.lower()

            is_correct = False

            if guess == answer_lower:
                is_correct = True
            else:
                validation_prompt = [
                    {"role": "system", "content": self.answerer_system_prompt.format(answer=answer)},
                    {
                        "role": "user",
                        "content": f'The player guessed: "{parsed.guess}". Is this guess EXACTLY correct for what you\'re thinking of?\n\nOnly answer "Yes" if the guess is essentially the same as "{answer}" - either exact match or very close synonym.\n\nEXAMPLES:\n✅ ACCEPT: "Gobi Desert" for "Gobi Desert", "Great Pyramid of Giza" for "Pyramids of Giza", "chips and cheese" for "nachos"\n❌ REJECT: "desert" for "Gobi Desert", "pyramid" for "Great Pyramid", "food" for "nachos", "car" for "Toyota Camry"\n\nPartial matches, general categories, and broader types are NOT correct - the guess must specifically identify "{answer}".',
                    },
                ]

                is_correct = False
                for attempt in range(3):
                    try:
                        validation_response = await self.get_model_response(
                            client=self.answerer_client,
                            model=self.answerer_model,
                            prompt=validation_prompt,
                            sampling_args=self.answerer_sampling_args,
                            message_type="chat",
                        )

                        if not validation_response.choices:
                            self.logger.warning("API returned empty response for validation, assuming incorrect guess")
                            is_correct = False
                            break
                        raw_validation = validation_response.choices[0].message.content or ""
                        parsed_validation = self.answerer_parser.parse(raw_validation)

                        if hasattr(parsed_validation, "answer") and parsed_validation.answer:
                            validation_text = parsed_validation.answer.strip().lower()
                            is_correct = validation_text.startswith("yes")
                            break
                        else:
                            if attempt == 2:
                                self.logger.warning(
                                    "Answerer failed to format validation response, assuming incorrect guess"
                                )
                                is_correct = False
                    except Exception as e:
                        self.logger.warning(f"Answerer API call failed (attempt {attempt + 1}): {e}")
                        if attempt == 2:
                            self.logger.warning("All answerer validation attempts failed, assuming incorrect guess")
                            is_correct = False

            state["questions_asked"] = questions_asked + 1

            if is_correct:
                state["game_won"] = True
                state["game_over"] = True
                state["final_message_sent"] = True
                return [{"role": "user", "content": WINNING_MESSAGE.format(answer=answer)}], state
            else:
                if state["questions_asked"] >= 20:
                    state["game_over"] = True
                    state["final_message_sent"] = True
                    return [
                        {
                            "role": "user",
                            "content": MAX_QUESTIONS_MESSAGE.format(answer=answer),
                        }
                    ], state
                else:
                    remaining_questions = 20 - state["questions_asked"]
                    return [
                        {
                            "role": "user",
                            "content": INCORRECT_GUESS_MESSAGE.format(remaining_questions=remaining_questions),
                        }
                    ], state

        if not hasattr(parsed, "question") or parsed.question is None:
            return [
                {
                    "role": "user",
                    "content": INVALID_XML_FORMAT_MESSAGE.format(format_str=self.parser.get_format_str()),
                }
            ], state

        question = parsed.question.strip()

        if "<" in question or ">" in question:
            self.logger.warning("Received question with XML markers: %s", question)
            return [
                {
                    "role": "user",
                    "content": INVALID_NESTED_XML_FORMAT_MESSAGE.format(format_str=self.parser.get_format_str()),
                }
            ], state

        answerer_prompt = [
            {"role": "system", "content": self.answerer_system_prompt.format(answer=answer)},
            {
                "role": "user",
                "content": ANSWERER_USER_PROMPT.format(question=question),
            },
        ]

        env_response_text = None
        last_error: Exception | None = None
        for attempt in range(ANSWERER_MAX_RETRIES):
            try:
                response = await self.get_model_response(
                    client=self.answerer_client,
                    model=self.answerer_model,
                    prompt=answerer_prompt,
                    sampling_args=self.answerer_sampling_args,
                    message_type="chat",
                )

                raw_response = response.choices[0].message.content or ""
                parsed_answer = self.answerer_parser.parse(raw_response)

                if hasattr(parsed_answer, "answer") and parsed_answer.answer:
                    env_response_text = parsed_answer.answer.strip()
                    break

                last_error = ValueError("Answerer returned an improperly formatted response.")
                self.logger.warning(
                    "Answerer failed to format response (attempt %d/%d). Prompt: %r. Raw response: %r",
                    attempt + 1,
                    ANSWERER_MAX_RETRIES,
                    answerer_prompt,
                    raw_response,
                )
            except Exception as e:
                last_error = e
                self.logger.warning(
                    "Answerer API call failed (attempt %d/%d): %s",
                    attempt + 1,
                    ANSWERER_MAX_RETRIES,
                    e,
                )

            if attempt < ANSWERER_MAX_RETRIES - 1:
                backoff_seconds = ANSWERER_RETRY_BACKOFF_SECONDS * (2**attempt)
                await asyncio.sleep(backoff_seconds)

        if env_response_text is None:
            error_message = "Answerer failed to produce a valid response after %d attempts." % ANSWERER_MAX_RETRIES
            self.logger.error(error_message)
            raise RuntimeError(error_message) from last_error

        state["questions_asked"] = questions_asked + 1

        remaining_questions = 20 - state["questions_asked"]
        formatted_response = REMAINING_QUESTIONS_RESPONSE_TEMPLATE.format(
            answer_text=env_response_text,
            remaining_questions=remaining_questions,
        )

        if state["questions_asked"] == 20:
            formatted_response = FINAL_GUESS_PROMPT_MESSAGE_TEMPLATE.format(answer_text=env_response_text)

        return [{"role": "user", "content": formatted_response}], state


def load_environment(
    answerer_model: str,
    answerer_base_url: str,
    answerer_api_key: str | None = None,
    **kwargs,
) -> TwentyQuestionsEnv:
    """
    Load the twenty questions environment.

    Args:
        answerer_model: Model name for answerer LLM (knows answers, answers questions)
        answerer_base_url: Base URL for answerer LLM API
        answerer_api_key: API key for answerer LLM (if None, uses OPENAI_API_KEY env var)

    Environment Variables:
        OPENAI_API_KEY: API key for the answerer LLM (used if answerer_api_key is None)
    """

    import os

    api_key = answerer_api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError(
            "API key is required for the answerer LLM. "
            "Either provide answerer_api_key parameter or set OPENAI_API_KEY environment variable."
        )

    answerer_client = setup_client(
        api_base_url=answerer_base_url,
        api_key=api_key,
        timeout=600.0,
        max_connections=100,
        max_keepalive_connections=50,
        max_retries=3,
    )

    from datasets import load_dataset

    dataset = load_dataset("ljt019/twenty-questions-600")

    dataset = dataset.map(lambda example: {"question": INITIAL_QUESTION_MESSAGE})

    parser = vf.XMLParser(
        fields=["think", ("question", "guess")],
        answer_field="guess",
    )

    def victory_reward(state, **kwargs) -> float:
        """Reward for successfully guessing the answer."""
        return 1.0 if state.get("game_won", False) else 0.0

    def efficiency_reward(state, **kwargs) -> float:
        """Reward for guessing with fewer questions (efficiency bonus)."""
        if not state.get("game_won", False):
            return 0.0
        questions_used = state.get("questions_asked", 20)

        efficiency = (20 - questions_used) / 20.0
        return efficiency * 0.5

    rubric = vf.Rubric(
        funcs=[
            victory_reward,
            efficiency_reward,
            parser.get_format_reward_func(),
        ],
        weights=[1.0, 0.5, 0.3],
        parser=parser,
    )

    env = TwentyQuestionsEnv(
        dataset=dataset["train"],
        eval_dataset=dataset["test"],
        system_prompt=QUESTIONER_SYSTEM_PROMPT.format(format_str=parser.get_format_str()),
        parser=parser,
        rubric=rubric,
        answerer_client=answerer_client,
        answerer_model=answerer_model,
        **kwargs,
    )

    return env
